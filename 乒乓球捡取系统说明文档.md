# 乒乓球捡取系统技术说明文档

## 1. 系统概述

乒乓球捡取系统是一个基于计算机视觉的自动化系统，使用RealSense深度相机检测乒乓球，并控制机器人进行捡取。系统采用了双层视觉识别架构：本地YOLO模型作为主要识别方式，云端大模型视觉增强作为补充，解决远距离乒乓球检测精度不足的问题。

## 2. 系统架构

系统由以下主要模块组成：

- **视觉处理模块**：负责图像采集、目标检测和三维坐标计算
- **控制器模块**：负责机器人运动控制和机械臂控制
- **云端决策系统**：提供高级决策支持和远距离视觉增强
- **硬件接口模块**：与RealSense相机、机械臂和移动平台通信

### 2.1 系统工作流程

1. 本地YOLO模型进行乒乓球检测
2. 如果检测到乒乓球，计算三维坐标并控制机器人逼近
3. 如果未检测到乒乓球或检测距离超过阈值，触发云端视觉增强
4. 云端大模型进行远距离乒乓球检测，返回结果
5. 系统合并本地和云端结果，进行最终决策
6. 控制机器人逼近并抓取乒乓球

## 3. 本地YOLO识别

### 3.1 技术原理

本地识别采用YOLO (You Only Look Once) 目标检测算法，具体使用了针对乒乓球检测优化的模型。YOLO是一种单阶段目标检测算法，能够在一次前向传播中同时预测多个目标的位置和类别，具有速度快、精度高的特点。

### 3.2 模型配置

- **模型文件**：`table_tennis.engine`（TensorRT优化版本）
- **置信度阈值**：0.5
- **输入尺寸**：640×640像素
- **设备**：GPU加速（device='0'）

### 3.3 检测流程

1. **图像获取**：从RealSense相机获取RGB图像和深度图像
   ```python
   frames = self.pipeline.wait_for_frames()
   aligned_frames = self.align.process(frames)
   aligned_depth_frame = aligned_frames.get_depth_frame()
   color_frame = aligned_frames.get_color_frame()
   ```

2. **目标检测**：使用YOLO模型检测乒乓球
   ```python
   results = self.model.predict(
       rgb,
       conf=Config.confidence_threshold,
       imgsz=640,
       device='0',
       verbose=False
   )
   ```

3. **三维坐标计算**：结合深度信息计算乒乓球的三维坐标
   ```python
   camera_coordinate = rs.rs2_deproject_pixel_to_point(depth_intrin, [center_x, center_y], dis)
   camera_coordinate[1] = -camera_coordinate[1]  # y轴取反
   camera_coordinate[1], camera_coordinate[2] = camera_coordinate[2], camera_coordinate[1]  # 交换y和z轴
   ```

4. **目标选择**：选择最佳的乒乓球目标（通常是最近的一个）
   ```python
   pos = choose_pingpang(results_boxes, maturity_degree, camera_coordinate_list)
   ```

### 3.4 本地识别优缺点

**优点**：
- 实时性强，延迟低（约30FPS）
- 不依赖网络连接，可在离线环境工作
- 对近距离乒乓球检测精度高
- 资源消耗相对较低

**缺点**：
- 远距离（>2米）检测精度下降
- 受光照条件影响较大
- 模型泛化能力有限，对未见过的场景适应性较差
- 无法处理复杂遮挡情况

## 4. 云端大模型视觉增强

### 4.1 技术原理

云端视觉增强采用了大型视觉语言模型（VLM）技术，通过API调用云端的高级视觉模型进行远距离乒乓球检测。系统使用Ark API接口，调用"doubao-seed-1-6-250615"模型，该模型具有更强的视觉理解能力和远距离目标检测能力。

### 4.2 触发条件

云端视觉增强在以下情况下触发：

1. 本地模型连续多次未检测到乒乓球
   ```python
   if self.no_detection_count >= self.max_no_detection_before_cloud:
       # 触发云端视觉增强
   ```

2. 检测到的乒乓球距离超过阈值（默认2米）
   ```python
   if min_distance > self.cloud_vision_threshold:
       # 触发云端视觉增强
   ```

3. 手动触发（通过键盘控制）

### 4.3 API调用流程

1. **图像预处理**：调整图像大小，转换为Base64编码
   ```python
   _, jpeg_data = cv2.imencode('.jpg', rgb_resized, [cv2.IMWRITE_JPEG_QUALITY, 80])
   rgb_base64 = base64.b64encode(jpeg_data).decode('utf-8')
   ```

2. **构建请求**：准备API请求参数
   ```python
   payload = {
       "model": "doubao-seed-1-6-250615",  # 使用豆包视觉模型
       "messages": [{
           "role": "user",
           "content": [
               {
                   "type": "text",
                   "text": "图片中是否有乒乓球？如果有，请给出它们的位置。格式为：<bbox>x_min y_min x_max y_max</bbox>"
               },
               {
                   "type": "image_url",
                   "image_url": {
                       "url": f"data:image/jpeg;base64,{rgb_base64}"
                   }
               }
           ]
       }],
       "thinking": {"type": "disabled"}  # 禁用思考过程，加快响应速度
   }
   ```

3. **发送请求**：调用云端API
   ```python
   response = requests.post(
       self.cloud_vision_endpoint,
       headers=headers,
       json=payload,
       timeout=10.0
   )
   ```

4. **解析结果**：从API响应中提取边界框坐标
   ```python
   content = result['choices'][0]['message']['content']
   bbox_start = content.find("<bbox>") + len("<bbox>")
   bbox_end = content.find("</bbox>")
   coords_str = content[bbox_start:bbox_end].strip()
   coords = list(map(int, coords_str.split()))
   ```

5. **坐标转换**：将边界框坐标转换为三维坐标
   ```python
   estimated_position = [
       horizontal_offset * estimated_distance * 0.5,  # x坐标，根据水平偏移估计
       estimated_distance,  # y坐标，估计距离
       0.0  # z坐标，假设在同一高度
   ]
   ```

### 4.4 距离估计算法

由于云端模型无法直接获取深度信息，系统使用边界框大小估计乒乓球距离：

```python
# 边界框越大，估计距离越近
box_area = box_width * box_height
estimated_distance = 1.0  # 默认估计距离为1米

# 改进的距离估计逻辑
if box_area > 0:
    # 使用非线性映射，更好地处理近距离情况
    reference_area = 10000  # 参考面积
    area_ratio = reference_area / box_area

    # 当边界框很大时（近距离），使用更保守的估计
    if box_area > 15000:  # 非常近的距离
        estimated_distance = 0.3 + (0.2 * area_ratio)  # 最小估计为0.3米
    elif box_area > 8000:  # 较近的距离
        estimated_distance = 0.5 + (0.3 * area_ratio)  # 最小估计为0.5米
    else:
        # 远距离使用原来的估计方法，但限制最大值
        estimated_distance = min(3.0, max(1.0, area_ratio * 0.5))
```

### 4.5 云端识别优缺点

**优点**：
- 远距离检测能力强，可识别2米以外的乒乓球
- 对复杂场景和光照条件适应性更好
- 具有更强的泛化能力，可处理未见过的场景
- 可以理解更复杂的视觉上下文

**缺点**：
- 依赖网络连接，离线环境无法使用
- 响应延迟较高（通常1-3秒）
- API调用次数有限，需要控制调用频率
- 距离估计精度不如本地深度相机直接测量

## 5. 本地与云端结果融合

### 5.1 融合策略

系统采用简单的结果合并策略，将本地检测结果和云端检测结果合并：

```python
def merge_detection_results(self, local_boxes, cloud_boxes):
    """
    合并本地和云端的检测结果
    :param local_boxes: 本地检测到的边界框
    :param cloud_boxes: 云端检测到的边界框
    :return: 合并后的边界框列表
    """
    # 简单合并两个列表
    return local_boxes + cloud_boxes

def merge_coordinate_lists(self, local_coords, cloud_coords):
    """
    合并本地和云端的坐标列表
    :param local_coords: 本地检测到的坐标列表
    :param cloud_coords: 云端检测到的坐标列表
    :return: 合并后的坐标列表
    """
    # 简单合并两个列表
    return local_coords + cloud_coords
```

### 5.2 冷却机制

为避免频繁调用云端API，系统实现了冷却机制：

```python
# 更新远程识别冷却时间
if self.cloud_vision_cooldown > 0:
    self.cloud_vision_cooldown -= 1

# 设置冷却时间，避免频繁触发
self.cloud_vision_triggered = False
self.cloud_vision_cooldown = 30  # 设置冷却时间
```

### 5.3 结果可视化

系统使用不同颜色区分本地和云端检测结果：
- 本地检测结果：绿色边界框
- 云端检测结果：蓝色边界框

```python
# 绘制本地检测结果
cv2.rectangle(rgb_display, (x1, y1), (x2, y2), (0, 255, 0), 2)

# 绘制云端检测结果
cv2.rectangle(marked_image, (x1, y1), (x2, y2), (255, 0, 0), 2)
```

## 6. 系统配置参数

### 6.1 本地YOLO配置

```python
# 模型配置
model = "./table_tennis.engine"  # 乒乓球检测模型
confidence_threshold = 0.5  # 乒乓球检测置信度阈值
```

### 6.2 云端视觉增强配置

```python
# 云端视觉增强配置
use_cloud_vision = True  # 是否使用云端视觉增强
cloud_vision_endpoint = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"  # Ark API端点
cloud_vision_threshold = 2.0  # 使用云端视觉的距离阈值（米）
cloud_vision_interval = 3.0  # 云端视觉请求间隔（秒）
cloud_vision_confidence = 0.7  # 云端视觉检测置信度阈值
cloud_vision_max_size = 640  # 发送到云端的图像最大尺寸（像素）
cloud_api_key = "2612d766-851a-495c-921a-a259eabd8e2a"  # Ark API密钥
```

## 7. 性能指标

### 7.1 本地YOLO性能

- **帧率**：约30FPS（在GPU加速下）
- **检测延迟**：约33ms/帧
- **有效检测距离**：0.3-2.0米
- **检测精度**：近距离（<1米）>95%，远距离（>2米）<70%

### 7.2 云端视觉增强性能

- **响应时间**：1-3秒
- **API调用频率**：每3秒最多1次
- **有效检测距离**：0.5-5.0米
- **检测精度**：远距离（>2米）>85%

## 8. 使用建议

1. **光照条件**：保持场地光照充足均匀，避免强烈的阴影和反光
2. **距离控制**：系统在0.5-2.0米范围内性能最佳
3. **网络连接**：确保稳定的网络连接以支持云端视觉增强
4. **API使用**：监控API调用次数，避免超出限额
5. **系统调优**：根据实际场景调整置信度阈值和距离阈值

## 9. 未来改进方向

1. **融合算法优化**：实现更智能的本地与云端结果融合算法，如加权融合或NMS（非极大值抑制）
2. **距离估计改进**：优化云端检测结果的距离估计算法，提高精度
3. **模型优化**：针对特定场景微调本地YOLO模型，提高检测精度
4. **缓存机制**：实现云端结果缓存和预测，减少API调用次数
5. **多模态融合**：结合其他传感器数据（如IMU、激光雷达）提高定位精度

## 10. 故障排除

### 10.1 本地检测问题

- **症状**：本地模型无法检测到乒乓球
- **可能原因**：光照不足、乒乓球距离过远、模型配置错误
- **解决方案**：调整光照、减小置信度阈值、检查模型路径

### 10.2 云端API问题

- **症状**：云端API调用失败
- **可能原因**：网络连接问题、API密钥无效、请求格式错误
- **解决方案**：检查网络连接、验证API密钥、检查请求格式

### 10.3 距离估计问题

- **症状**：距离估计不准确
- **可能原因**：深度相机校准问题、云端估计算法不准确
- **解决方案**：重新校准深度相机、调整距离估计参数
